{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d23a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Conv2D, MaxPool2D, Dense,MaxPooling2D,Bidirectional\n",
    "from keras.layers import AveragePooling2D, Flatten, Activation\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Concatenate, Add, Multiply, Lambda\n",
    "from keras.layers import UpSampling2D, Reshape\n",
    "from keras.layers.merge import add,concatenate\n",
    "from keras.layers import Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM,GRU\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import cv2\n",
    "import pytesseract\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a959f5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_data/501_nonadhesive.jpg</td>\n",
       "      <td>NONADHESIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_data/502_Aglitter.jpg</td>\n",
       "      <td>AGLITTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_data/503_azania.jpg</td>\n",
       "      <td>AZANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_data/504_Pliocenes.jpg</td>\n",
       "      <td>PLIOCENES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_data/505_Cozenage.jpg</td>\n",
       "      <td>COZENAGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ImageName       Labels\n",
       "0  Test_data/501_nonadhesive.jpg  NONADHESIVE\n",
       "1     Test_data/502_Aglitter.jpg     AGLITTER\n",
       "2       Test_data/503_azania.jpg       AZANIA\n",
       "3    Test_data/504_Pliocenes.jpg    PLIOCENES\n",
       "4     Test_data/505_Cozenage.jpg     COZENAGE"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('Data_1823.csv')\n",
    "test_data.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b88052",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters= '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f603c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_from_labels(labels):\n",
    "\n",
    "    txt=[]\n",
    "    for ele in labels:\n",
    "        if ele == len(letters): # CTC blank space\n",
    "            txt.append(\"\")\n",
    "        else:\n",
    "            #print(letters[ele])\n",
    "            txt.append(letters[ele])\n",
    "    return \"\".join(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e05fba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_label(out):\n",
    "    # out : (1, 48, 37)\n",
    "    out_best = list(np.argmax(out[0,2:], axis=1))\n",
    "\n",
    "    out_best = [k for k, g in itertools.groupby(out_best)]  # remove overlap value\n",
    "\n",
    "    outstr=words_from_labels(out_best)\n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21642c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image height\n",
    "img_h=32\n",
    "#image width\n",
    "img_w=170\n",
    "#image Channels\n",
    "img_c=1\n",
    "# classes for softmax with number of letters +1 for blank space in ctc\n",
    "num_classes=len(letters)+1\n",
    "batch_size=64\n",
    "max_length=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4872817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_create(drop_out_rate=0.35):\n",
    "\n",
    "     \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "       \n",
    "    model_input=Input(shape=input_shape,name='img_input',dtype='float32')\n",
    "\n",
    "    # Convolution layer \n",
    "    model = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(model_input) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(2, 2), name='max1')(model) \n",
    "\n",
    "    model = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(model) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(2, 2), name='max2')(model) \n",
    "\n",
    "    model = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(model) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(model)\n",
    "    model=Dropout(drop_out_rate)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(1, 2), name='max3')(model)  \n",
    "\n",
    "    model = Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(model) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(512, (3, 3), padding='same', name='conv6')(model)\n",
    "    model=  Dropout(drop_out_rate)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size=(1, 2), name='max4')(model) \n",
    "\n",
    "    model = Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='conv7')(model)\n",
    "    model=  Dropout(0.25)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)    \n",
    "\n",
    "    # CNN to CRNN\n",
    "    model = Reshape(target_shape=((42, 1024)), name='reshape')(model)  \n",
    "    model = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(model)  \n",
    "\n",
    "    # RNN layer\n",
    "    model=Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='sum')(model)\n",
    "    model=Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='concat')(model)\n",
    "\n",
    "    # transforms CRNN output to character activations:\n",
    "    model = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(model) \n",
    "    y_pred = Activation('softmax', name='softmax')(model)\n",
    "\n",
    "    return Model(inputs=[model_input], outputs=y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c69e16e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_single_image_Prediction(model,test_img_path):\n",
    "    start=datetime.now()\n",
    "    \n",
    "    test_img=cv2.imread(test_img_path)\n",
    "    test_img_resized=cv2.resize(test_img,(170,32))\n",
    "    test_image=test_img_resized[:,:,1]\n",
    "    test_image=test_image.T \n",
    "    test_image=np.expand_dims(test_image,axis=-1)\n",
    "    test_image=np.expand_dims(test_image, axis=0)\n",
    "    test_image=test_image/255\n",
    "    model_output=model.predict(test_image)\n",
    "    predicted_output = decode_label(model_output)\n",
    "    predicted_output = pytesseract.image_to_string(test_image)\n",
    "    print(\"Predicted Text in the Image: \", predicted_output)\n",
    "    print(\"Time Taken for Processing: \",datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb833c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b5d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_multiple_image_Prediction(model,test_img_names,test_labels,total):\n",
    "\n",
    "\n",
    "    start=datetime.now()\n",
    "    accuracy=0\n",
    "    letter_acc=0\n",
    "    letter_cnt=0\n",
    "    count=0\n",
    "    for i in range(len(test_labels)):\n",
    "        test_img=cv2.imread(test_img_names[i])\n",
    "        test_img_resized=cv2.resize(test_img,(170,32))\n",
    "        test_image=test_img_resized[:,:,1]\n",
    "        test_image=test_image.T\n",
    "        test_image=np.expand_dims(test_image,axis=-1)\n",
    "        test_image=np.expand_dims(test_image, axis=0)\n",
    "        test_image=test_image/255\n",
    "        model_output=model.predict(test_image)\n",
    "        predicted_output=decode_label(model_output)\n",
    "        actual_output=test_labels[i]\n",
    "        count+=1\n",
    "        for j in range(min(len(predicted_output),len(actual_output))):\n",
    "            if predicted_output[j]==actual_output[j]:\n",
    "                letter_acc+=1\n",
    "        letter_cnt+=max(len(predicted_output),len(actual_output))\n",
    "        if actual_output==predicted_output:\n",
    "            accuracy+=1\n",
    "        print(\"-\"*80)\n",
    "        print(\"Actual Text: \",actual_output,\"   Predicted Text: \",predicted_output)\n",
    "    print(\"=\"*80)\n",
    "    print(\"Model Output Accuracy: \",(accuracy/total)*100, \" %\")\n",
    "    print(\"Model Output Letter Accuracy: \",(letter_acc/letter_cnt)*100, \" %\")\n",
    "    print(\"Time Taken for Processing: \",datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "309c2d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img_input (InputLayer)       [(None, 170, 32, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 170, 32, 64)       640       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 170, 32, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 170, 32, 64)       0         \n",
      "_________________________________________________________________\n",
      "max1 (MaxPooling2D)          (None, 85, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 85, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 85, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 85, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max2 (MaxPooling2D)          (None, 42, 8, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 42, 8, 256)        295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 42, 8, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 42, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 42, 8, 256)        590080    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 42, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 42, 8, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 42, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "max3 (MaxPooling2D)          (None, 42, 4, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 42, 4, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 42, 4, 512)        2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 42, 4, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 42, 4, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 42, 4, 512)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 42, 4, 512)        2048      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 42, 4, 512)        0         \n",
      "_________________________________________________________________\n",
      "max4 (MaxPooling2D)          (None, 42, 2, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv7 (Conv2D)               (None, 42, 2, 512)        1049088   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 42, 2, 512)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 42, 2, 512)        2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 42, 2, 512)        0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 42, 1024)          0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 42, 64)            65600     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 42, 256)           657408    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 42, 512)           1050624   \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 42, 37)            18981     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 42, 37)            0         \n",
      "=================================================================\n",
      "Total params: 7,350,373\n",
      "Trainable params: 7,345,893\n",
      "Non-trainable params: 4,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=model_create()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33d83a3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 32, 1), <f8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py:2813\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2812\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2813\u001b[0m     mode, rawmode \u001b[38;5;241m=\u001b[39m \u001b[43m_fromarray_typemap\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtypekey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2814\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyError\u001b[0m: ((1, 1, 32, 1), '<f8')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCRNN.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m test_image_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest_Data/text.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtest_data_single_image_Prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_image_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(test_image_1)\n\u001b[0;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputImage\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mtest_data_single_image_Prediction\u001b[1;34m(model, test_img_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m model_output\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(test_image)\n\u001b[0;32m     15\u001b[0m predicted_output \u001b[38;5;241m=\u001b[39m decode_label(model_output)\n\u001b[1;32m---> 16\u001b[0m predicted_output \u001b[38;5;241m=\u001b[39m \u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Text in the Image: \u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_output)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime Taken for Processing: \u001b[39m\u001b[38;5;124m\"\u001b[39m,datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m-\u001b[39mstart)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytesseract\\pytesseract.py:423\u001b[0m, in \u001b[0;36mimage_to_string\u001b[1;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    421\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m--> 423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytesseract\\pytesseract.py:426\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    421\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    424\u001b[0m     Output\u001b[38;5;241m.\u001b[39mBYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[0;32m    425\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: run_and_get_output(\u001b[38;5;241m*\u001b[39margs)},\n\u001b[1;32m--> 426\u001b[0m     Output\u001b[38;5;241m.\u001b[39mSTRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    427\u001b[0m }[output_type]()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytesseract\\pytesseract.py:277\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[1;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_and_get_output\u001b[39m(\n\u001b[0;32m    268\u001b[0m     image,\n\u001b[0;32m    269\u001b[0m     extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m     return_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m ):\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[0;32m    278\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    279\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: input_filename,\n\u001b[0;32m    280\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[0;32m    286\u001b[0m         }\n\u001b[0;32m    288\u001b[0m         run_tesseract(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytesseract\\pytesseract.py:197\u001b[0m, in \u001b[0;36msave\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\u001b[38;5;241m.\u001b[39mname, realpath(normpath(normcase(image)))\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m image, extension \u001b[38;5;241m=\u001b[39m \u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m input_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_input\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    199\u001b[0m image\u001b[38;5;241m.\u001b[39msave(input_file_name, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mformat)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pytesseract\\pytesseract.py:171\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare\u001b[39m(image):\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m numpy_installed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, ndarray):\n\u001b[1;32m--> 171\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, Image\u001b[38;5;241m.\u001b[39mImage):\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnsupported image object\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py:2815\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2813\u001b[0m         mode, rawmode \u001b[38;5;241m=\u001b[39m _fromarray_typemap[typekey]\n\u001b[0;32m   2814\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2815\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot handle this data type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m typekey) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2816\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2817\u001b[0m     rawmode \u001b[38;5;241m=\u001b[39m mode\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 32, 1), <f8"
     ]
    }
   ],
   "source": [
    "model.load_weights('CRNN.h5')\n",
    "test_image_1='Test_Data/text.png'\n",
    "test_data_single_image_Prediction(model,test_image_1)\n",
    "img = cv2.imread(test_image_1)\n",
    "cv2.imshow(\"InputImage\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Grayscale, Gaussian blur, Otsu's threshold\n",
    "image = cv2.imread('cse.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "# thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# # # Morph open to remove noise and invert image\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "# opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "# invert = 255 - opening\n",
    "\n",
    "# Perform text extraction\n",
    "data = pytesseract.image_to_string(image, lang='eng')\n",
    "print(data)\n",
    "\n",
    "# cv2.imshow('thresh', thresh)\n",
    "# cv2.imshow('opening', opening)\n",
    "# cv2.imshow('invert', invert)\n",
    "# cv2.waitKey()\n",
    "\n",
    "#286, 282\n",
    "#295\n",
    "# 2_ORATORICALLY_53626\n",
    "#473_Blackberries_7777\n",
    "#61_curlicued_18718\n",
    "# 23_STRONGBOX_75284\n",
    "# 47_RAREFACTION_62482"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
